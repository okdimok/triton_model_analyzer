version: '3'
services:
  onnx-trt:
    image: "nvcr.io/nvidia/pytorch:23.05-py3"    
    deploy: # https://docs.docker.com/compose/gpu-support/#enabling-gpu-access-to-service-containers
      resources:
        reservations:
          devices:
          - driver: nvidia
            device_ids: ['0'] 
            capabilities: [gpu]
    network_mode: host # or use ports
    # ports: # or use network_mode: host
    #   - "9988:8888"
    #   - "8787:8787" # dask
    #   - "6006:6006"
    #   - "49152:49152" # Nsight Compute
    volumes:
      - "../:/workspace/ext"
      - "${HOME}:/ext_home"
    ulimits:
      memlock: -1
    environment:
      PROMPT_COMMAND: "history -a; history -n"
      HISTSIZE: "" # one has to first set the size empty
      HISTFILESIZE: "" # and file size empty, otherwise the precious history will get truncated
      HISTFILE: "/ext_home/docker/unix/docker_bash_history"
      IPYTHONDIR: "/ext_home/docker/unix/ipython_dir" # to keep the ipython history. Make sure docker user and group can set permissions they need in this location. Doesn't work with cifs mounts.
      DISPLAY: "${DISPLAY}" # you need to escape the variable using a double-dollar sign, if it has to be take from the container
    stdin_open: true # for interactive sessions, like -i. Required if the container CMD stops without tty
    tty: true # for interactive sessions, like -t. Required if the container CMD stops without tty
    cap_add: 
      - SYS_ADMIN  # to enable profiling
    ipc: host # for faster multiprocess communication. One can also just set relatively large shm-size
    shm_size: 4G
    working_dir: /workspace/ext
    command: /bin/bash -c "sleep infinity"
